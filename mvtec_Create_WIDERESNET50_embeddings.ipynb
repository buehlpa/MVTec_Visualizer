{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "#from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# PATHs\n",
    "PROJECT_DATA_PATH='//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection'\n",
    "LOG_DIR= '/home/bule/projects/MVTec_Visualizer/tensorboard_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to images\n",
    "image_paths = []\n",
    "for root, dirs, files in os.walk(PROJECT_DATA_PATH):\n",
    "    if 'ground_truth' not in root:\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME='MVTEC_WIDERESNET50_3thBlock_embeddings_df'\n",
    "\n",
    "\n",
    "if not os.path.exists(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl')):\n",
    "    # Load the pre-trained WideResNet50 model\n",
    "    model = models.wide_resnet50_2(pretrained=True)\n",
    "    # Modify the model to extract features from the third residual block\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:7]))\n",
    "    # Function to extract features\n",
    "\n",
    "    def extract_features(img_path, model):\n",
    "        # Load image with PIL and convert to RGB\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transformations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize([224, 224]),#resize for wideresent\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #normalize  images for imagenet\n",
    "        ])\n",
    "\n",
    "        img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(img)\n",
    "        return features[0].flatten()#.squeeze().numpy()\n",
    "\n",
    "\n",
    "    all_embeddings = []\n",
    "    # Extract features and save to DataFrame\n",
    "    for img_path in image_paths:\n",
    "        batch_embeddings = extract_features(img_path, model)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    tensor_list_2d = [t.unsqueeze(0) for t in all_embeddings]\n",
    "    all_embeddings = torch.cat(tensor_list_2d, dim=0)\n",
    "    \n",
    "    df = pd.DataFrame(all_embeddings, index=image_paths)\n",
    "    df.to_pickle(os.path.join(PROJECT_DATA_PATH, FILENAME + '.pkl'))\n",
    "    \n",
    "else:\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "    \n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
