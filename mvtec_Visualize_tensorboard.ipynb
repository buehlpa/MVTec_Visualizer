{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVTEc    Visualizer\n",
    "\n",
    "- claculates clip embeddings\n",
    "- vizualisation via tensorboard projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: True\n",
      "Torch version: 2.1.0+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 16:10:41.678618: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-12 16:10:41.696910: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-12 16:10:41.696928: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-12 16:10:41.696942: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-12 16:10:41.700697: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 16:10:42.032679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# activate clip env\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*pandas only supports SQLAlchemy connectable.*\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f'GPU is available: {torch.cuda.is_available()}')\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.tensorboard \n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_images_for_tensorboard(image_paths):\n",
    "    # Preprocess the images\n",
    "    transform_display = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(64),  # Resize the images \n",
    "        torchvision.transforms.CenterCrop(64),  # Crop the images\n",
    "        torchvision.transforms.ToTensor()  # Convert images to tensors        \n",
    "    ])\n",
    "\n",
    "    images = []  # Array to store the preprocessed images\n",
    "    for path in image_paths:\n",
    "        image = Image.open(path).convert('RGB')  # Open the image and convert to RGB\n",
    "        # Apply the display transformation\n",
    "        image_display = transform_display(image)\n",
    "        image_display = image_display.unsqueeze(0) # Add a batch dimension to the image\n",
    "        images.append(image_display)\n",
    "\n",
    "    images = torch.cat(images, dim=0)  # Concatenate the images along the batch dimension\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHs\n",
    "PROJECT_DATA_PATH='//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection'\n",
    "LOG_DIR= '/home/bule/projects/MVTec_Visualizer/tensorboard_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5354"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paths to images\n",
    "image_paths = []\n",
    "for root, dirs, files in os.walk(PROJECT_DATA_PATH):\n",
    "    if 'ground_truth' not in root:\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "len(image_paths)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images 0 to 1024\n",
      "Processed images 1024 to 2048\n",
      "Processed images 2048 to 3072\n",
      "Processed images 3072 to 4096\n",
      "Processed images 4096 to 5120\n",
      "Processed images 5120 to 5354\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection/transistor/test/damaged_case/001.png</th>\n",
       "      <td>0.186768</td>\n",
       "      <td>-0.099304</td>\n",
       "      <td>-0.444092</td>\n",
       "      <td>-0.162842</td>\n",
       "      <td>0.243652</td>\n",
       "      <td>-0.088989</td>\n",
       "      <td>0.325928</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>-0.354004</td>\n",
       "      <td>0.196777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354980</td>\n",
       "      <td>-0.232910</td>\n",
       "      <td>0.734863</td>\n",
       "      <td>-0.283691</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.693848</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.341797</td>\n",
       "      <td>-0.132080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection/transistor/test/damaged_case/009.png</th>\n",
       "      <td>0.204224</td>\n",
       "      <td>0.108948</td>\n",
       "      <td>-0.504395</td>\n",
       "      <td>-0.085022</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>-0.298340</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>-0.199219</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326660</td>\n",
       "      <td>-0.277344</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>-0.329834</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>-0.642090</td>\n",
       "      <td>-0.032318</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.173584</td>\n",
       "      <td>-0.114746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection/transistor/test/damaged_case/007.png</th>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.116394</td>\n",
       "      <td>-0.501953</td>\n",
       "      <td>-0.183838</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>-0.191895</td>\n",
       "      <td>0.183105</td>\n",
       "      <td>0.643555</td>\n",
       "      <td>-0.268066</td>\n",
       "      <td>0.210327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>-0.449219</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>-0.274658</td>\n",
       "      <td>-0.049103</td>\n",
       "      <td>-0.625977</td>\n",
       "      <td>-0.104919</td>\n",
       "      <td>0.709473</td>\n",
       "      <td>0.172241</td>\n",
       "      <td>-0.039185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection/transistor/test/damaged_case/003.png</th>\n",
       "      <td>0.122864</td>\n",
       "      <td>-0.008751</td>\n",
       "      <td>-0.594238</td>\n",
       "      <td>-0.012032</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>-0.247681</td>\n",
       "      <td>0.293945</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>-0.291016</td>\n",
       "      <td>-0.003828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080322</td>\n",
       "      <td>-0.366455</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>-0.174805</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>-0.578613</td>\n",
       "      <td>0.047913</td>\n",
       "      <td>0.584961</td>\n",
       "      <td>0.180420</td>\n",
       "      <td>-0.087341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>//home/bule/projects/MVTec_Visualizer/data/mvtec_anomaly_detection/transistor/test/damaged_case/000.png</th>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.095276</td>\n",
       "      <td>-0.407227</td>\n",
       "      <td>-0.280029</td>\n",
       "      <td>0.268311</td>\n",
       "      <td>-0.163940</td>\n",
       "      <td>0.309814</td>\n",
       "      <td>0.631836</td>\n",
       "      <td>-0.463379</td>\n",
       "      <td>0.166260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>-0.335693</td>\n",
       "      <td>0.934082</td>\n",
       "      <td>-0.235352</td>\n",
       "      <td>-0.063538</td>\n",
       "      <td>-0.691406</td>\n",
       "      <td>-0.154785</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.130737</td>\n",
       "      <td>-0.209106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1    \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.186768 -0.099304   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.204224  0.108948   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.012260  0.116394   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.122864 -0.008751   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.033691  0.095276   \n",
       "\n",
       "                                                         2         3    \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.444092 -0.162842   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.504395 -0.085022   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.501953 -0.183838   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.594238 -0.012032   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.407227 -0.280029   \n",
       "\n",
       "                                                         4         5    \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.243652 -0.088989   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.519531 -0.298340   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.270020 -0.191895   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.351562 -0.247681   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.268311 -0.163940   \n",
       "\n",
       "                                                         6         7    \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.325928  0.600098   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.139526  0.593750   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.183105  0.643555   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.293945  0.671875   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.309814  0.631836   \n",
       "\n",
       "                                                         8         9    ...  \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.354004  0.196777  ...   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.199219  0.260742  ...   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.268066  0.210327  ...   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.291016 -0.003828  ...   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.463379  0.166260  ...   \n",
       "\n",
       "                                                         502       503  \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.354980 -0.232910   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.326660 -0.277344   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.252930 -0.449219   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.080322 -0.366455   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.287598 -0.335693   \n",
       "\n",
       "                                                         504       505  \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.734863 -0.283691   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.656250 -0.329834   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.693359 -0.274658   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.833008 -0.174805   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.934082 -0.235352   \n",
       "\n",
       "                                                         506       507  \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.000609 -0.693848   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.215210 -0.642090   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.049103 -0.625977   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.009460 -0.578613   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.063538 -0.691406   \n",
       "\n",
       "                                                         508       509  \\\n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.053375  0.746094   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.032318  0.791016   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.104919  0.709473   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.047913  0.584961   \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte... -0.154785  0.882812   \n",
       "\n",
       "                                                         510       511  \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.341797 -0.132080  \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.173584 -0.114746  \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.172241 -0.039185  \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.180420 -0.087341  \n",
       "//home/bule/projects/MVTec_Visualizer/data/mvte...  0.130737 -0.209106  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1024  # Adjust this based on your GPU memory\n",
    "FILENAME = 'MVTEC_CLIP_embeddings_df'\n",
    "\n",
    "if not os.path.exists(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl')):\n",
    "\n",
    "    # Load the model\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, transform = clip.load('ViT-B/32', device=device)\n",
    "\n",
    "\n",
    "    # Function to get embeddings for a batch of images\n",
    "    def get_batch_embeddings(batch_paths):\n",
    "        images = [Image.open(p) for p in batch_paths]\n",
    "        tensors = [transform(img) for img in images]\n",
    "        batch_tensor = torch.stack(tensors).to(device)\n",
    "        with torch.no_grad():\n",
    "            batch_features = model.encode_image(batch_tensor)\n",
    "        return batch_features.cpu().numpy()\n",
    "\n",
    "    # Calculate embeddings for all images in batches\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(image_paths), BATCH_SIZE):\n",
    "        batch_paths = image_paths[i:i+BATCH_SIZE]\n",
    "        batch_embeddings = get_batch_embeddings(batch_paths)\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "        print(f\"Processed images {i} to {i + len(batch_embeddings)}\")\n",
    "\n",
    "    # Convert all embeddings to DataFrame and save\n",
    "    df = pd.DataFrame(all_embeddings, index=image_paths)\n",
    "    df.to_pickle(os.path.join(PROJECT_DATA_PATH, FILENAME + '.pkl'))\n",
    "else:\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVTEC_embeddings_df\n",
      "MVTEC_embeddings_df  number of images:5354\n"
     ]
    }
   ],
   "source": [
    "# make tensorboard logs\n",
    "\n",
    "print(FILENAME)\n",
    "TENSORBOARD_LOGS_PATH=os.path.join(LOG_DIR,'_'+FILENAME).replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "if not  os.path.exists(TENSORBOARD_LOGS_PATH):\n",
    "\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "\n",
    "    # Convert the resulting series of lists to a NumPy array\n",
    "    numpy_array = df.to_numpy()\n",
    "\n",
    "    # resize images \n",
    "    images = convert_images_for_tensorboard(image_paths)\n",
    "\n",
    "    # for tensorboard\n",
    "    writer = SummaryWriter(TENSORBOARD_LOGS_PATH)\n",
    "    writer.add_embedding(numpy_array, label_img=images)\n",
    "\n",
    "else:\n",
    "    df = pd.read_pickle(os.path.join(PROJECT_DATA_PATH,FILENAME+'.pkl'))\n",
    "\n",
    "print(f'{FILENAME}  number of images:{len(image_paths)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run tensorboard on port forward to browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 16:21:33.977256: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-12 16:21:33.978493: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-12 16:21:33.995517: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-12 16:21:33.995536: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-12 16:21:33.995548: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-12 16:21:33.998995: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-12 16:21:33.999148: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 16:21:34.331175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-12 16:21:34.670608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-12 16:21:34.686413: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard  --logdir $TENSORBOARD_LOGS_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformalyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
